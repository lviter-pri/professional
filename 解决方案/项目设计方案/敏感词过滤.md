# 敏感词过滤

## DFA

（JDK 1.8, Spring Boot, Redis, RocketMQ, MySQL），采用 **“管理后台配置 + 缓存分发 + 内存本地过滤”** 的架构方案。

## 1. 核心架构设计

为了保证生产环境的性能，敏感词过滤不能每次都查数据库。

- **存储层 (MySQL)：** 永久存储敏感词库、分类、白名单等。
- **缓存层 (Redis)：** 存储敏感词的版本号或简单的增量更新标记。
- **消息层 (RocketMQ)：** 当后台修改敏感词时，发送广播消息通知所有微服务节点更新本地内存。
- **过滤层 (Local Memory)：** 采用 **DFA (确定有穷自动机)** 算法在内存中构建搜索树。

## 2. 核心算法选择：DFA

在 Java 中，处理敏感词最经典且高效的方法是 DFA 算法。它将词库构建成一颗树，匹配时间复杂度仅与文本长度有关，与词库大小几乎无关。

### 数据结构示例

如果词库有“大象”、“大哥”，树结构如下：

```json
{
  "词": {
    "库": {
      "isEnd": true
    }
  },
  "敏": {
    "不": {
      "感": {
        "1": {
          "isEnd": true
        }
      }
    },
    "感": {
      "isEnd": true
    }
  }
}
```



## 3. 详细设计方案

### A. 数据库设计 (MySQL)

建立一张简单的表来维护词条。

| **字段** | **类型** | **说明**                      |
| -------- | -------- | ----------------------------- |
| id       | bigint   | 主键                          |
| word     | varchar  | 敏感词内容                    |
| category | varchar  | 类别 (涉政、色情、暴恐等)     |
| level    | int      | 敏感级别 (1-拒绝, 2-人工审核) |
| status   | int      | 状态 (0-启用, 1-禁用)         |



### B. 刷新机制 (RocketMQ + Redis)

1. **后台更新：** 管理员在后台新增一个词。

2. **触发通知：** 后台更新 MySQL 后，向 RocketMQ 的 `SENSITIVE_WORD_TOPIC` 发送一条 **广播消息 (Broadcasting)**。

3. **节点更新：** 每个微服务实例监听到消息后，重新从数据库加载数据，并在内存中重建 DFA 树。

   > **注意：** 也可以在 Redis 存一个 `last_update_time`，服务启动时先对比版本。

### C. 核心代码逻辑 (Java)

你可以封装一个 `SensitiveWordProvider` 组件：

```java
@Component
public class SensitiveWordFilter {
    // DFA 树根节点
    private Map<Object, Object> nodes = new HashMap<>();

    @PostConstruct
    public void init() {
        refresh(); // 项目启动加载
    }

    public synchronized void refresh() {
        // 1. 从数据库读取所有有效敏感词
        List<String> words = wordMapper.selectAllEnabled();
        // 2. 构建新的 DFA 树
        Map<Object, Object> newNodes = new HashMap<>();
        for (String word : words) {
            addWord(newNodes, word);
        }
        // 3. 切换引用 (保证原子性)
        this.nodes = newNodes;
    }

    private void addWord(Map<Object, Object> tree, String word) {
        Map<Object, Object> current = tree;
        for (char c : word.toCharArray()) {
            current = (Map<Object, Object>) current.computeIfAbsent(c, k -> new HashMap<>());
        }
        current.put("isEnd", true);
    }

    public boolean contains(String text) {
        // 实现 DFA 查找逻辑...
        return false;
    }
}
```



双重循环过滤逻辑：

```java
import java.util.HashSet;
import java.util.Map;
import java.util.Set;

public class SensitiveWordFilter {

    private Map<Object, Object> nodes; // DFA 树根节点
    private static final String END_FLAG = "isEnd"; // 结束标识

    /**
     * 判断是否包含敏感词
     * @param text 待检测文本
     * @return true 包含
     */
    public boolean contains(String text) {
        if (text == null || text.isEmpty()) return false;

        for (int i = 0; i < text.length(); i++) {
            // 检查以位置 i 开头的字符串是否匹配敏感词
            int matchLen = checkSensitive(text, i);
            if (matchLen > 0) {
                return true;
            }
        }
        return false;
    }

    /**
     * 获取文本中出现的所有敏感词
     * @param text 待检测文本
     * @return 匹配到的词集合
     */
    public Set<String> findAll(String text) {
        Set<String> result = new HashSet<>();
        for (int i = 0; i < text.length(); i++) {
            int length = checkSensitive(text, i);
            if (length > 0) {
                result.add(text.substring(i, i + length));
                // 优化：i 直接跳过已匹配词的长度，减少重复计算
                i = i + length - 1; 
            }
        }
        return result;
    }

    /**
     * 检查从 beginIndex 开始是否是敏感词
     * @return 如果匹配成功，返回敏感词长度；否则返回 0
     */
    private int checkSensitive(String text, int beginIndex) {
        Map<Object, Object> current = this.nodes;
        int matchLen = 0;
        boolean flag = false;

        for (int i = beginIndex; i < text.length(); i++) {
            char c = text.charAt(i);
            
            // 1. 在当前层级查找字符
            current = (Map<Object, Object>) current.get(c);
            
            if (current != null) {
                matchLen++;
                // 2. 检查是否是词的结尾
                if ("true".equals(String.valueOf(current.get(END_FLAG)))) {
                    flag = true; 
                    // 这里可以根据需求决定：是命中“最短”敏感词就返回，还是找“最长”的
                    // 默认找到最长的，所以继续循环
                }
            } else {
                // 3. 没匹配到，跳出
                break;
            }
        }

        return flag ? matchLen : 0;
    }
}
```



## 4. 现成轮子推荐

如果不想从零实现 DFA 树，推荐直接集成成熟的 Java 工具包：

- **Hutool-dfa:** 简单易用。
- **sensitive-word:** (GitHub 上很火的一个库) 支持拼音检测、繁简体转换、跳词检测等功能，功能非常全面。



### 5.本地构建DFA树示例

```java
package com.kyexpress.vts.finance.api.dto.baidu;


import com.kyexpress.framework.utils.JsonUtils;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

public class Test {
    // DFA 树根节点
    private static Map<Object, Object> nodes = new HashMap<>();

    public static void main(String[] args) {
        String mingan = "这是一串敏感词";
        refresh();
        System.out.println(JsonUtils.deserializer(nodes));
    }

    private static void addWord(Map<Object, Object> nodes, String word) {
        Map<Object, Object> current = nodes;
        for (char c : word.toCharArray()) {
            current = (Map<Object, Object>) current.computeIfAbsent(c, k -> new HashMap<>());
        }
        current.put("isEnd", true);
    }

    public static void refresh() {
        // 1. 从数据库读取所有有效敏感词
        List<String> words = new ArrayList<>();
        words.add("敏感");
        words.add("词库");
        words.add("敏不感1");
        // 2. 构建新的 DFA 树
        Map<Object, Object> newNodes = new HashMap<>();
        for (String word : words) {
            addWord(newNodes, word);
        }
        nodes = newNodes;
    }
}

```

